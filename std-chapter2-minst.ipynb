{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dbccbff",
   "metadata": {},
   "source": [
    "### Chapter 3: Classification\n",
    "Notes for *Hands on Machine Learning with Scikit by Aurelien Geron*. This is on Chapter 3: Classification, where it explains the fundamentals on how Machine Learning identify one group from the other using statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b77701",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "The dataset used is the *MNIST*, which is a collection of handwritten numbers in the format of image pixels. The goal is to have the machine tell us what number is in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb7802f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b25158",
   "metadata": {},
   "source": [
    "You can download a copy of the dataset from sklearn. This gets updated often, which is why it is different on the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "885a67b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, target = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c618b2",
   "metadata": {},
   "source": [
    "There are 2 sets of data. *Data* contains the pixel information about the number image, which is what we will use to predict. *Target* are the answer keys, which tells us what the number is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfbf7aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data (70000, 784)\n",
      "target (70000,)\n"
     ]
    }
   ],
   "source": [
    "print('data', df.shape) # I store the data info in df, which is short for dataframe.\n",
    "print('target', target.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580cb074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    784.000000\n",
       "mean      35.108418\n",
       "std       79.699674\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.000000\n",
       "max      255.000000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fff533f",
   "metadata": {},
   "source": [
    "There are 70,000 numbers in the dataset and each number holds 784 pixels. Each pixel has a value between 0 to 255, which indicates the intensity of the black color. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260a2696",
   "metadata": {},
   "source": [
    "## Split Train Test\n",
    "Before we begin, we set aside a portion of the dataset into a *Test* set, which is what we use at the very end to validate our models. We use the *Train* for majority of our exploration and data engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c5a3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, train_target, test_target = df[:60000], df[60000:], target[:60000], target[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7bc944",
   "metadata": {},
   "source": [
    "The MINST dataset is already dividied into Train and Test. The first 60k rows is the Train and the rest are the Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e9f48cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "shuffle_index = np.random.RandomState(seed=42).permutation(60000)\n",
    "train_df, train_target = train_df.iloc[shuffle_index], train_target.iloc[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5daf7f",
   "metadata": {},
   "source": [
    "There is a chance that the numbers are in order in a way that it will affect our models. Like a new deck of cards, we would always shuffle it before using them. Here, we shuffle it using the index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075b094",
   "metadata": {},
   "source": [
    "# Explore Data\n",
    "Our data is prepapred. It is time to Explore, Clean and Machine Learning the shit out of it. \n",
    "\n",
    "I don't restrict myself from exploring the data but I do keep everything organized. That is why I keep Exploring, Cleaning and Machine Learning code in separate sections in this order. This section is where we keep all our Exploring data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "650dae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "seven = train_df.loc[59963].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b7842",
   "metadata": {},
   "source": [
    "The numbers will keep shuffling everytime you run the code. Better choose a number and remember the index so you can iterate over the same number. Here I choose the number 7, which has an index of 59963 as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25a74360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKsAAACrCAYAAAAZ6GwZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFJklEQVR4nO3dvSu9fxzH8Yt+iygM1HG3UEooZ7BQFOWmLAzK+QdYyWAwkRWLQUxnMDBJBoszkCxuImKQ5KYY5C5lcH777/M+39/ndDjH6+v5GN9d1+WiZ5/6nONcJysej8cDQEB2pm8A8EWskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskEGskPFPpm8AtqOjI2e2trbmff7NzY0zm5ubM4+NRCLOLBqNev+sdGFlhQxihQxihQxihQxihYyseDwez/RNKPv4+HBm8/Pz3udPTEyY87e3N2f2/v7uf2NJyMnJcWZdXV3ObHl5+Vt+vi9WVsggVsggVsggVsj4K99uvbq6MuexWMzr/IeHB3M+OzvrzD4/P53Z3d2deb61l83KyvK6p++Une2uWYODgxm4kz9jZYUMYoUMYoUMYoUMYoUMmVcDLi4uzPnAwIAzS7Qbv76+/tJ7SqS2ttacV1ZWOrNErwY0NDQ4s6amJme2tLRknr+4uPinW/zf67a1tXmfny6srJBBrJBBrJBBrJAhs8HKzc0155eXl84s0dulvurr6815cXGxM+vp6XFmfX195vmhUMj7HqxN4vb2tjPb2Njwvmai32tkZMT7GpnEygoZxAoZxAoZxAoZ8h8Y3NracmYHBwfmsfn5+c6stLTUmdXV1ZnnFxUVJXdzKZiamnJm4+Pj3ufn5eU5s9XVVfPYlpYW/xvLIFZWyCBWyCBWyCBWyCBWyJB/NUDd2dmZOW9tbXVm9/f3zsza9QdBEHR3dzuzRP/7qoKVFTKIFTKIFTKIFTLYYKWR9Q0qNTU15rGvr69e1+zt7TXnmX6W6ndgZYUMYoUMYoUMYoUMNlgpsv58Ly8v5rEFBQXOLJnns1rvVm1ubprHhsNh7+uqYGWFDGKFDGKFDGKFDGKFDF4NSNHz87MzKywsNI9N9dtaTk5OnFl1dbX3+epYWSGDWCGDWCGDWCFD5vmsP8HT05Mza29vd2aJ9qzJ7GWtL7D4TZspCysrZBArZBArZBArZBArZPBqgOHx8dGcW58kPT4+dmbJvIV6e3trzq1vhvntWFkhg1ghg1ghg1gh49dvsPb3952Z9WzTILCfj2rp6Ogw5wsLC84s0UYqO5t15L/4i0AGsUIGsUIGsULGr9pg7ezsOLNIJOLMfDdSQRAEjY2Nzmx6eto8tqSkxPu6cLGyQgaxQgaxQgaxQgaxQsZf+figWCxmzoeGhpzZ+fm593Wtt0YPDw+9jkPqWFkhg1ghg1ghg1ghQ/7t1r29PWc2NjZmHuu7maqoqDDn0WjUmbGZSh9WVsggVsggVsggVsggVsiQeTVgfX3dnFufGD09PfW+bnl5uTObmZkxj21ubva+Lr4eKytkECtkECtkECtk/MgNlvX/qJOTk+axu7u73tetqqpyZqOjo84sHA57XxPpw8oKGcQKGcQKGcQKGT9yg2WxnqOaLOsLLDo7O51ZWVlZyj8LX4+VFTKIFTKIFTKIFTKIFTJkHh/U399vzldWVpzZ8PCweaw1D4VCqd0Y0oaVFTKIFTKIFTKIFTJkNlgAKytkECtkECtkECtkECtkECtkECtkECtkECtkECtkECtkECtkECtkECtkECtkECtkECtkECtkECtkECtk/AuUxv6gougjLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seven_target = train_target.loc[59963] # Choose a number and remember the index because of the shuffle.\n",
    "print(seven_target)\n",
    "plt.figure(figsize=(2,2))\n",
    "number_seven_image = seven.reshape(28, 28)\n",
    "plt.imshow(number_seven_image, cmap = mpl.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb220176",
   "metadata": {},
   "source": [
    "Each row contains pixel information about a number. If it reshaped into 28 by 28 pixels and plotted in a graph, the image of the number will show. We have chosen the number seven and true enough the image is a seven."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bb677c",
   "metadata": {},
   "source": [
    "# Clean Data\n",
    "In this section, we Clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83a83df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_target = train_target.astype(np.uint8)\n",
    "test_target = test_target.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfbe6f6",
   "metadata": {},
   "source": [
    "The values of each targets are strings. We want them as intigers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54892799",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "In this section, we do our Machine Learning algorithms. We start with an easy algorithm, then we work our way up to the more complex ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1d8909",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent\n",
    "The goal is to use the pixel information in each row to tell us what number it is. But before doing all numbers, we start with something simple, which is to determine if the number is seven or not (TRUE or FALSE). For our first model, we use SGD that is great at classifying large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6bc81083",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_seven = (train_target == int(seven_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a55d6a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(random_state=42) # Init. Call on SGD.\n",
    "sgd_clf.fit(train_df, train_target_seven) # Fit. We give instructions to Machine.\n",
    "sgd_clf.predict([seven]) # Predict. Ask machine if seven is the number seven."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca5db8",
   "metadata": {},
   "source": [
    "Pay attention here because this is how all Machine Learning Algorithm works:\n",
    "- Init. We create an instance of the model.\n",
    "- Fit. We give the Machine the data and the answer keys for it to learn.\n",
    "- Predict. We then check if the Machine can tell if variable *seven* is seven. In this case, it does and it outputs the value *True*.\n",
    "\n",
    "Now, let us check if the Machine can tell if the rest of the numbers are seven and check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb93c0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98115, 0.97325, 0.97295])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, train_df, train_target_seven, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd4aff7",
   "metadata": {},
   "source": [
    "*cross_val_score* splits the training data into 3 folds and uses 2 folds as training data and 1 fold as the test. It does this 3 times in different combination. \n",
    "\n",
    "Results show that on average, the model is accurate around ~95% of the time. This is unusually high. Let us try another dumber model and check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83da03d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c3e7b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89895, 0.8912 , 0.8966 ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "never_roll_clf = Never5Classifier()\n",
    "cross_val_score(never_roll_clf, train_df, train_target_seven, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b63a199",
   "metadata": {},
   "source": [
    "Again, we get very high results. This is because ~90% of the numbers are not sevens. So, if the model says that all numbers are not sevens (All FALSE), then the accuracy would still be around ~90%. This is why accuracy, as a measure of classification, sucks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8338e77",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "Instead just counting the correct predictions, Confusion Matrix also takes into account the wrong predictions. This creates balance in the way we evaluate our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e64b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "train_pred_seven = cross_val_predict(sgd_clf, train_df, train_target_seven, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01217488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53145,   590],\n",
       "       [  863,  5402]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(train_target_seven, train_pred_seven)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dd9a34",
   "metadata": {},
   "source": [
    "#### \n",
    "![confusion_matrix](image1.svg)\n",
    "\n",
    "**Precision** is the number of times the model predicted that the number was seven versus all the predictions that it thought was seven. **Recall** is the number of times the model predicted that the number was seven versus all the actual sevens that exists in the dataset.\n",
    "\n",
    "Precision alone is not enough to evaluate a model. If say the model had only 1 True prediction, which happens to be a seven, then your precision is 100%. Recall is also not useful either by itself. It is possible to get a 100% recall if the model predicted that ALL numbers are sevens, which gives you a Recall of 100%.\n",
    "\n",
    "There are some use cases where you would prioritize one metric over the other but, generally, you want to have both Precision and Recall to be both high. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cf05128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9015353805073432"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision = precision_score(train_target_seven, train_pred_seven)\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174bcd5a",
   "metadata": {},
   "source": [
    "For our model, it has a 90% precision score, which means that out 5,992 numbers that it has identified as the number seven, only 5,402 of those wer actually the number seven. This is pretty good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ad89fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8622505985634478"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = recall_score(train_target_seven, train_pred_seven)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3e209f",
   "metadata": {},
   "source": [
    "But it has scored a recall of 86%, which means that the 5,402 correct predictions are only 86% of all actual sevens. It was not able to identify 863 that were also sevens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d00fa6",
   "metadata": {},
   "source": [
    "## F1 score\n",
    "Harmonic mean gives more weigh to low values. Regular mean will weight the 2 values equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e19f3ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.8818929895353955\n",
      "f1:  0.881455494819287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('mean: ', (precision + recall) / 2)\n",
    "print('f1: ', f1_score(train_target_seven, train_pred_seven))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993f965f",
   "metadata": {},
   "source": [
    "### Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e40dcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4694.93201914])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scores = sgd_clf.decision_function([seven])\n",
    "y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "873c4792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0\n",
    "y_some_digit_pred = (y_scores > threshold)\n",
    "y_some_digit_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d36def7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f460f58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
